{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijR6qPINU_P6",
        "outputId": "bbdcce11-0ec8-4e15-fb1d-501d1c24e1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment1-basics'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (201/201), done.\u001b[K\n",
            "remote: Total 359 (delta 191), reused 311 (delta 143), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (359/359), 12.82 MiB | 9.20 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eve-liya/assignment1-basics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd assignment1-basics/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5eKjGhFMiZ6",
        "outputId": "d1d97864-0a25-4c9b-c3a7-e3dbf4f93cc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/assignment1-basics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVh85UKdMng8",
        "outputId": "752cf14c-bd7a-4204-f51c-eef9f0fdeceb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLdwVyZ3MKk8",
        "outputId": "86724958-eb87-4b76-db07-e9f6c9d1591f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup environment"
      ],
      "metadata": {
        "id": "qUpCszLnfDf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e .'[test]' --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1tPK7iKenBW",
        "outputId": "b2006ff1-c779-4527-f2ab-a45621d5c02b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pass all tests"
      ],
      "metadata": {
        "id": "Rxwhf1igODQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-_dABLeW3LR",
        "outputId": "ca274120-b9b3-4836-db47-697bd90f5b08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content/assignment1-basics\n",
            "configfile: pytest.ini\n",
            "plugins: langsmith-0.3.8, typeguard-4.4.1, anyio-3.7.1\n",
            "collected 42 items                                                                                 \u001b[0m\n",
            "\n",
            "tests/test_data.py::test_get_batch \u001b[32mPASSED\u001b[0m\u001b[32m                                                    [  2%]\u001b[0m\n",
            "tests/test_model.py::test_positionwise_feedforward \u001b[32mPASSED\u001b[0m\u001b[32m                                    [  4%]\u001b[0m\n",
            "tests/test_model.py::test_scaled_dot_product_attention \u001b[32mPASSED\u001b[0m\u001b[32m                                [  7%]\u001b[0m\n",
            "tests/test_model.py::test_4d_scaled_dot_product_attention \u001b[32mPASSED\u001b[0m\u001b[32m                             [  9%]\u001b[0m\n",
            "tests/test_model.py::test_multihead_self_attention \u001b[32mPASSED\u001b[0m\u001b[32m                                    [ 11%]\u001b[0m\n",
            "tests/test_model.py::test_transformer_lm \u001b[32mPASSED\u001b[0m\u001b[32m                                              [ 14%]\u001b[0m\n",
            "tests/test_model.py::test_transformer_lm_truncated_input \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 16%]\u001b[0m\n",
            "tests/test_model.py::test_transformer_block \u001b[32mPASSED\u001b[0m\u001b[32m                                           [ 19%]\u001b[0m\n",
            "tests/test_model.py::test_rmsnorm \u001b[32mPASSED\u001b[0m\u001b[32m                                                     [ 21%]\u001b[0m\n",
            "tests/test_model.py::test_gelu \u001b[32mPASSED\u001b[0m\u001b[32m                                                        [ 23%]\u001b[0m\n",
            "tests/test_model.py::test_gelu_matches_pytorch \u001b[32mPASSED\u001b[0m\u001b[32m                                        [ 26%]\u001b[0m\n",
            "tests/test_nn_utils.py::test_softmax_matches_pytorch \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 28%]\u001b[0m\n",
            "tests/test_nn_utils.py::test_cross_entropy \u001b[32mPASSED\u001b[0m\u001b[32m                                            [ 30%]\u001b[0m\n",
            "tests/test_nn_utils.py::test_gradient_clipping \u001b[32mPASSED\u001b[0m\u001b[32m                                        [ 33%]\u001b[0m\n",
            "tests/test_optimizer.py::test_adamw \u001b[32mPASSED\u001b[0m\u001b[32m                                                   [ 35%]\u001b[0m\n",
            "tests/test_optimizer.py::test_get_lr_cosine_schedule \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 38%]\u001b[0m\n",
            "tests/test_serialization.py::test_checkpointing \u001b[32mPASSED\u001b[0m\u001b[32m                                       [ 40%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_empty \u001b[32mPASSED\u001b[0m\u001b[32m                                         [ 42%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_empty_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 45%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_single_character \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 47%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_single_character_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 50%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_single_unicode_character \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 52%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_single_unicode_character_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m               [ 54%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_ascii_string \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 57%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_ascii_string_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 59%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_unicode_string \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 61%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_unicode_string_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 64%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_roundtrip_unicode_string_with_special_tokens \u001b[32mPASSED\u001b[0m\u001b[32m            [ 66%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_unicode_string_with_special_tokens_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m     [ 69%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_overlapping_special_tokens \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 71%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_address_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m                                       [ 73%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_address_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 76%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_german_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m                                        [ 78%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_german_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 80%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_tinystories_sample_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 83%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_tinystories_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 85%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_encode_iterable_tinystories_sample_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m            [ 88%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_encode_iterable_tinystories_matches_tiktoken \u001b[32mPASSED\u001b[0m\u001b[32m            [ 90%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_encode_iterable_memory_usage \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 92%]\u001b[0m\n",
            "tests/test_tokenizer.py::test_encode_memory_usage \u001b[33mXFAIL\u001b[0m (Tokenizer.encode is expected to...)\u001b[32m [ 95%]\u001b[0m\n",
            "tests/test_train_bpe.py::test_train_bpe_speed \u001b[32mPASSED\u001b[0m\u001b[32m                                         [ 97%]\u001b[0m\n",
            "tests/test_train_bpe.py::test_train_bpe \u001b[32mPASSED\u001b[0m\u001b[32m                                               [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================== \u001b[32m\u001b[1m41 passed\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[32m in 37.56s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}